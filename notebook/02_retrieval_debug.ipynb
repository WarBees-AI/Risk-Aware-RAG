{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 02 â€” Retrieval Debug\n",
        "\n",
        "This notebook:\n",
        "1) loads BM25 fallback index\n",
        "2) runs retrieval queries\n",
        "3) inspects top documents and snippets\n",
        "4) provides a simple evidence-inspection workflow\n"
      ],
      "metadata": {
        "id": "Oukqb8xusj7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "CORPUS_PATH = Path(\"data/processed/corpus.jsonl\")\n",
        "INDEX_DIR = Path(\"data/processed/index\")\n",
        "BM25_PATH = INDEX_DIR / \"bm25.json\"\n",
        "\n",
        "def load_jsonl(path: Path, max_rows: int = 200000):\n",
        "    rows = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            rows.append(json.loads(line))\n",
        "            if i+1 >= max_rows:\n",
        "                break\n",
        "    return rows\n",
        "\n",
        "corpus = load_jsonl(CORPUS_PATH, max_rows=50000)\n",
        "print(\"Corpus docs:\", len(corpus))"
      ],
      "metadata": {
        "id": "erdhaFeQsknV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25 = json.loads(BM25_PATH.read_text(encoding=\"utf-8\"))\n",
        "print(\"BM25 keys:\", bm25.keys())\n",
        "print(\"N:\", bm25[\"N\"], \"avgdl:\", bm25[\"avgdl\"])"
      ],
      "metadata": {
        "id": "_XIsVWxnsoZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text: str):\n",
        "    text = text.lower()\n",
        "    return re.findall(r\"[a-z0-9]+\", text)\n",
        "\n",
        "def bm25_score(query: str, bm25_obj: dict, doc_idx: int, k1=1.2, b=0.75):\n",
        "    N = bm25_obj[\"N\"]\n",
        "    avgdl = bm25_obj[\"avgdl\"]\n",
        "    df = bm25_obj[\"df\"]\n",
        "    doc_len = bm25_obj[\"doc_len\"][doc_idx]\n",
        "    toks = bm25_obj[\"tokenized\"][doc_idx]\n",
        "    tf = {}\n",
        "    for t in toks:\n",
        "        tf[t] = tf.get(t, 0) + 1\n",
        "\n",
        "    score = 0.0\n",
        "    q = tokenize(query)\n",
        "    for term in q:\n",
        "        if term not in df:\n",
        "            continue\n",
        "        n_q = df[term]\n",
        "        # IDF\n",
        "        idf = math.log((N - n_q + 0.5) / (n_q + 0.5) + 1e-9)\n",
        "        f = tf.get(term, 0)\n",
        "        denom = f + k1 * (1 - b + b * (doc_len / (avgdl + 1e-9)))\n",
        "        score += idf * (f * (k1 + 1) / (denom + 1e-9))\n",
        "    return score"
      ],
      "metadata": {
        "id": "yo8HfJvisugr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_bm25(query: str, top_k: int = 5):\n",
        "    scores = []\n",
        "    for i in range(bm25[\"N\"]):\n",
        "        s = bm25_score(query, bm25, i)\n",
        "        if s != 0:\n",
        "            scores.append((s, i))\n",
        "    scores.sort(reverse=True, key=lambda x: x[0])\n",
        "    hits = scores[:top_k]\n",
        "    results = []\n",
        "    for s, idx in hits:\n",
        "        doc_id = bm25[\"docs\"][idx][\"id\"]\n",
        "        meta = bm25[\"docs\"][idx].get(\"meta\", {})\n",
        "        # fetch original text\n",
        "        # corpus order matches build_index load order (same corpus file)\n",
        "        text = corpus[idx][\"text\"]\n",
        "        results.append({\"rank\": len(results)+1, \"score\": s, \"doc_id\": doc_id, \"meta\": meta, \"text\": text})\n",
        "    return results\n",
        "\n",
        "# Try a query\n",
        "query = \"risk-aware retrieval gating in RAG\"\n",
        "results = retrieve_bm25(query, top_k=5)\n",
        "pd.DataFrame([{\"rank\": r[\"rank\"], \"score\": r[\"score\"], \"doc_id\": r[\"doc_id\"], \"file\": r[\"meta\"].get(\"filename\",\"\")} for r in results])"
      ],
      "metadata": {
        "id": "jNYwZ6UMsxmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in results:\n",
        "    print(\"=\"*90)\n",
        "    print(f'Rank {r[\"rank\"]} | score={r[\"score\"]:.4f} | id={r[\"doc_id\"]} | file={r[\"meta\"].get(\"filename\",\"\")}')\n",
        "    print(r[\"text\"][:800])"
      ],
      "metadata": {
        "id": "w2mKUsiks0Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evidence_check(doc_text: str):\n",
        "    flags = []\n",
        "    low = doc_text.lower()\n",
        "    # very rough heuristic flags (replace with your evidence_filter LLM judge later)\n",
        "    if any(k in low for k in [\"step-by-step\", \"exploit\", \"payload\", \"bypass\", \"jailbreak\", \"malware\"]):\n",
        "        flags.append(\"procedural_or_attack_enabler\")\n",
        "    if any(k in low for k in [\"ssn\", \"passport\", \"credit card\", \"phone number\", \"email:\"]):\n",
        "        flags.append(\"pii_risk\")\n",
        "    return flags\n",
        "\n",
        "for r in results:\n",
        "    flags = evidence_check(r[\"text\"])\n",
        "    print(r[\"doc_id\"], \"flags:\", flags)"
      ],
      "metadata": {
        "id": "au5WJl_Zs3WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell will work only after you implement RAIRAGPipeline.\n",
        "try:\n",
        "    from rai_rag.pipeline.rai_rag import RAIRAGPipeline\n",
        "    pipe = RAIRAGPipeline.from_config(\"configs/base.yaml\")\n",
        "    out = pipe.run(\"Explain RAI-RAG retrieval gating and evidence filtering.\")\n",
        "    out.keys()\n",
        "except Exception as e:\n",
        "    print(\"Internal pipeline not available yet:\", e)"
      ],
      "metadata": {
        "id": "egah9nJHs5ci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}