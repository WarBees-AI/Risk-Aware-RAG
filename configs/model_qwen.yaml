# Override model section for Qwen instruct models
# Merge this on top of base.yaml in your config loader.

model:
  provider: "hf"
  name_or_path: "Qwen/Qwen2.5-7B-Instruct"
  tokenizer_name_or_path: null

  max_input_tokens: 8192
  max_output_tokens: 1024
  temperature: 0.2
  top_p: 0.9
  repetition_penalty: 1.05

  lora:
    enabled: false
    path: null

